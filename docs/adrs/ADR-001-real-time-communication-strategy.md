# ADR-001: Real-Time Communication Strategy — HTTP Polling vs WebSockets vs SSE

| Field | Value |
|---|---|
| **Status** | Accepted (v1.1) — Supersedes HTTP Polling |
| **Date** | 2026-02-27 |
| **Authors** | Platform Team |
| **Deciders** | Platform Team |

---

## Context

The DECP platform requires two categories of real-time (or near-real-time) data delivery to clients:

1. **Notifications** — alerting users when someone likes their post, applies to their job, or RSVPs to their event. These are low-urgency, asynchronous events generated by the Pub/Sub pipeline.
2. **Chat messages** — delivering new messages in the 1:1 Messaging service. These are user-initiated and much more time-sensitive.

At the time of this decision, the backend is being deployed on **Google Cloud Run** — a fully managed, stateless, serverless container platform. The platform scales to zero when idle and routes requests across multiple anonymous container instances.

This constraint is the primary driver behind this ADR.

---

## Problem

Three technical options were evaluated:

### Option A — HTTP Polling (Superseded)

The frontend periodically sends a standard HTTP `GET` request to fetch new data:
Client ──(GET /notifications every 30s)──> Gateway ──> Notification Service ──> MongoDB
Client ──(GET /messages every 1s)──> Gateway ──> Messaging Service ──> MongoDB

### Option B — Server-Sent Events (SSE)

The server holds an HTTP connection open and streams new data as it arrives. One-directional (server → client only).

### Option C — WebSockets (Chosen Architecture)

The client and server establish a persistent TCP connection. Either side can push data at any time. Implemented via socket.io through a dedicated Realtime Service.

---

## Decision Drivers

| Driver | Polling | SSE | WebSockets |
|---|---|---|---|
| Cloud Run compatibility | ✅ Fully stateless | ⚠️ Works, but needs Redis for multi-instance fan-out | ❌ Requires sticky sessions or Redis + `min-instances > 0` |
| Implementation complexity | ✅ Trivial | Medium | High |
| Infrastructure cost | ✅ None extra | Needs Redis (~$35/month) | Needs Redis + revised gateway config |
| Browser support | ✅ Universal | ✅ Universal | ✅ Universal |
| Delivery latency (notifications) | 0–30 seconds | <1 second | <100ms |
| Delivery latency (messages) | 0–1 second | <1 second | <100ms |
| Suitable for notifications | ✅ Yes | ✅ Yes | ✅ Yes |
| Suitable for chat | ⚠️ Adequate only | ✅ Yes | ✅ Ideal |
| Server load at scale | Medium (predictable) | Low | Low |

---

## Decision

**For v1.1: WebSockets via dedicated socket.io Realtime Service.**

### Rationale

Initial plans called for HTTP polling due to Cloud Run statelessness constraints. However, upon further review of the Messaging requirement, it was determined that 1-second polling would provide a substandard user experience and generate excessive baseline database load. 

A dedicated `decp-realtime` service using `socket.io` was introduced. 

1. **Clean Architecture:** The realtime service acts as a pure presentation layer. The Notification and Messaging services save their data to MongoDB directly, and then make a fast, fire-and-forget internal HTTP `POST /emit` call to the Realtime service.
2. **Gateway Compatibility:** The existing API Gateway `http-proxy-middleware` seamlessly proxies WebSocket upgrades (`ws: true`) on the `/realtime` path while preserving JWT validation.
3. **Future Scaling (Cloud Run):** If deployed to Cloud Run, the realtime service will require Cloud Memorystore (Redis) and `min-instances: 1` to prevent connection drops. During local development, the in-memory socket registry is sufficient.

---

## Current Implementation

### Backend Flow
1. Notification or Message is saved to MongoDB.
2. Service calls `emitToUser(userId, eventName, payload)`.
3. HTTP POST goes to `decp-realtime/emit`.
4. Realtime service looks up connected sockets for `userId`.
5. Data is pushed over the active WebSocket interface.

### Frontend Flow (React/Next.js)
```typescript
const socket = io('http://localhost:8082', {
  path: '/realtime/socket.io',
  auth: { token: accessToken }
});

socket.on('message', (msg) => updateChat(msg));
socket.on('notification', (notif) => updateBadge(notif));
```

---

## Consequences

### Positive
- True real-time delivery with <100ms latency for Chat and Notifications.
- Eradicates "empty polling" database queries.
- Multi-tab sync works automatically (sending a message in one tab broadcasts `message:sent` to all your other tabs).

### Negative
- Architectural complexity increases (14 containers now running).

### Technical Debt Created
- `TD-001`: When deploying to a multi-instance production environment, the in-memory `userSockets.Map` in `decp-realtime` must be replaced with the `@socket.io/redis-adapter` backed by Cloud Memorystore.

---

## Upgrade Path (v2 — When to Trigger)

**Trigger conditions** for replacing polling:
- Messaging complaints from users (feeling of lag)
- Server load from polling becomes measurable (>1000 concurrent users)
- Product decision to add typing indicators or read receipts

### Recommended v2 Architecture: Server-Sent Events + Redis

```
Client ──── GET /api/v1/notifications/stream ────> Gateway
                                                       │
                                            Notification Service
                                              (SSE endpoint)
                                                       │
                                              Redis Pub/Sub (Cloud Memorystore)
                                                       │
                                            Notification Service
                                              (Pub/Sub push handler)
                                              writes event to Redis channel for userId
```

**Why SSE over WebSockets for v2:**
- SSE is unidirectional (server → client), which is all notifications and message delivery need
- SSE is built on HTTP/1.1 — fully Cloud Run compatible with `min-instances: 1`
- Client reconnection is automatic and built into the browser's `EventSource` API
- Simpler to implement than WebSockets — no handshake protocol, no frame encoding

**Infrastructure needed for v2:**
- Google Cloud Memorystore (Redis) — approximately $35–70/month
- Set `min-instances: 1` on the Notification + Messaging Cloud Run services to prevent connection drops during cold start
- Redis client library in the Notification and Messaging services (`ioredis`)

### Recommended v3 Architecture: WebSockets (If bidirectional is needed)

Only warranted if the product needs:
- Typing indicators (`user is typing...`)
- Presence indicators (online/offline)
- Live collaborative features (e.g., shared research document editing)

WebSocket implementation on Cloud Run requires:
- `min-instances: 1` on all WebSocket-capable services
- Redis Pub/Sub for fan-out across instances (same as SSE)
- An Nginx or Envoy sidecar configured for WebSocket upgrades at the Gateway level
- Session affinity (`--session-affinity` flag in Cloud Run) for connection stickiness

---

## Alternatives Considered and Rejected

| Option | Reason Rejected |
|---|---|
| WebSockets (v1) | Incompatible with Cloud Run stateless model without significant extra infrastructure |
| Long Polling | More complex than regular polling with similar latency; no benefit at this scale |
| Firebase Realtime Database / Firestore | Would introduce Firebase as a dependency, adding vendor lock-in and cost; inconsistent with the GCP-native architecture |
| MQTT | Designed for IoT; overkill and adds broker infrastructure with no benefit over SSE |

---

## References

- [Google Cloud Run WebSocket support](https://cloud.google.com/run/docs/triggering/websockets)
- [MDN — Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [Cloud Run Session Affinity](https://cloud.google.com/run/docs/configuring/session-affinity)
- [Cloud Memorystore for Redis](https://cloud.google.com/memorystore/docs/redis)
